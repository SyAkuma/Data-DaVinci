{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "5SCQd7yTFzUR",
        "outputId": "d779bdc8-b526-4086-ebd8-e7c82b178709",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, InputLayer, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Data-DaVinci/homer_bart_1"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ydgFBXssNKbc",
        "outputId": "0bbeb769-8b5b-44e1-ce99-ad5955898458",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "homer100.bmp  homer119.bmp  homer23.bmp  homer3.bmp   homer56.bmp  homer72.bmp\thomer87.bmp\n",
            "homer101.bmp  homer120.bmp  homer24.bmp  homer40.bmp  homer57.bmp  homer73.bmp\thomer8.bmp\n",
            "homer102.bmp  homer121.bmp  homer26.bmp  homer41.bmp  homer58.bmp  homer74.bmp\thomer90.bmp\n",
            "homer103.bmp  homer122.bmp  homer27.bmp  homer43.bmp  homer59.bmp  homer75.bmp\thomer91.bmp\n",
            "homer104.bmp  homer123.bmp  homer28.bmp  homer44.bmp  homer5.bmp   homer76.bmp\thomer92.bmp\n",
            "homer105.bmp  homer124.bmp  homer29.bmp  homer45.bmp  homer60.bmp  homer77.bmp\thomer93.bmp\n",
            "homer106.bmp  homer13.bmp   homer2.bmp\t homer46.bmp  homer61.bmp  homer78.bmp\thomer94.bmp\n",
            "homer107.bmp  homer14.bmp   homer30.bmp  homer47.bmp  homer62.bmp  homer79.bmp\thomer95.bmp\n",
            "homer109.bmp  homer15.bmp   homer31.bmp  homer48.bmp  homer63.bmp  homer7.bmp\thomer96.bmp\n",
            "homer10.bmp   homer16.bmp   homer32.bmp  homer49.bmp  homer65.bmp  homer80.bmp\thomer97.bmp\n",
            "homer110.bmp  homer17.bmp   homer33.bmp  homer4.bmp   homer66.bmp  homer81.bmp\thomer98.bmp\n",
            "homer112.bmp  homer18.bmp   homer34.bmp  homer50.bmp  homer68.bmp  homer82.bmp\thomer99.bmp\n",
            "homer113.bmp  homer1.bmp    homer35.bmp  homer51.bmp  homer69.bmp  homer83.bmp\thomer9.bmp\n",
            "homer115.bmp  homer20.bmp   homer36.bmp  homer52.bmp  homer6.bmp   homer84.bmp\n",
            "homer116.bmp  homer21.bmp   homer37.bmp  homer54.bmp  homer70.bmp  homer85.bmp\n",
            "homer117.bmp  homer22.bmp   homer38.bmp  homer55.bmp  homer71.bmp  homer86.bmp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9Jlihor9FzUW",
        "outputId": "8876c7bd-a2ef-4b45-c126-d3f7d1eefe16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 269 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "### TODO 1: Split the training data into folders train and test with subfolders for each class\n",
        "### Additionally, also convert the data (normalise the pixel values)\n",
        "datagen=ImageDataGenerator(rescale=1./255)\n",
        "data=next(datagen.flow_from_directory(directory=\"/content/drive/MyDrive/Data-DaVinci/\",batch_size=269))\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(data[0], data[1], test_size=0.2)\n",
        "train_data =(X_train,Y_train)\n",
        "test_data =(X_test,Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "qtaUDYHGFzUY"
      },
      "outputs": [],
      "source": [
        "input_shape = (256,256,3) # Check dimensions of the images\n",
        "model = Sequential([\n",
        "    InputLayer(input_shape=input_shape),\n",
        "    # TODO 2: Add more layers to the neural network (start with flattening it)\n",
        "    # YOUR CODE HERE\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(2, activation='softmax') # Optionally you could also have a layer with only 1 node with activation function as sigmoid\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "7k1IDXl5FzUZ",
        "outputId": "af4c876f-4329-4730-968e-83a2af9e1775",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 254ms/step - accuracy: 0.5907 - loss: 19.0371\n",
            "Epoch 2/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 378ms/step - accuracy: 0.6195 - loss: 15.8039\n",
            "Epoch 3/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 287ms/step - accuracy: 0.7096 - loss: 7.2767\n",
            "Epoch 4/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 343ms/step - accuracy: 0.6241 - loss: 3.5646\n",
            "Epoch 5/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - accuracy: 0.8310 - loss: 1.1714\n",
            "Epoch 6/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 235ms/step - accuracy: 0.8306 - loss: 1.5147\n",
            "Epoch 7/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 341ms/step - accuracy: 0.8705 - loss: 0.9386\n",
            "Epoch 8/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 361ms/step - accuracy: 0.8912 - loss: 0.5242\n",
            "Epoch 9/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 289ms/step - accuracy: 0.8852 - loss: 0.6032\n",
            "Epoch 10/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 231ms/step - accuracy: 0.9166 - loss: 0.6128\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f651c4035e0>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "model.compile(optimizer=Adam(), loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
        "# TODO 3: Modify train_data and the value of epochs accordingly\n",
        "model.fit(train_data[0],train_data[1], epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "oA8vlgNWFzUa",
        "outputId": "bc9151b7-32ef-4a84-c8c8-a7c3958fc811",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.7593 - loss: 1.8993\n",
            "Test accuracy: 0.7592592835426331\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_data[0],test_data[1], steps=1)\n",
        "print(f'Test accuracy: {test_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iyj3ro5gYptn"
      },
      "execution_count": 57,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}